{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SUM_AILA_Task2_BCleaned.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidrusiya/AILA_KFolds/blob/main/SUM_AILA_Task2_BCleaned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCG_2TEURbY_"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import nltk\n",
        "import re\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOIsrZYOSoGw",
        "outputId": "1db85cdb-0fe2-45d8-c37f-b4f44ca2b0f7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5roN2skVhBGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9170d5ec-57f4-4ec7-aa06-9003ed04afa0"
      },
      "source": [
        "import seaborn as sns\n",
        "import gensim\n",
        "nltk.download('all')\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, Dense, Dropout, Bidirectional, LSTM\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from google.colab import drive\n",
        "from nltk import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "!pip3 install tensorflow_text\n",
        "import tensorflow_text\n",
        "!pip install -q tf-models-official\n",
        "!pip install -q -U tensorflow-text\n",
        "from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as tf_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw-1.4.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet31.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n",
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.7.3-cp37-cp37m-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.8,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.42.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.13.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.10.0.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.37.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.19.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.22.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (12.0.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.1)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.7.3\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 40.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 46.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.6 MB 1.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 90 kB 9.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 213 kB 48.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 8.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 46.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 38.0 MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VDMdGjS8vxK"
      },
      "source": [
        "dataset = open('/content/drive/MyDrive/nit_agartala_nlp_team_3.tsv', 'r')\n",
        "df = pd.read_csv(dataset, sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "zmUK3Cer86Cn",
        "outputId": "d86142b1-3bdd-4bf9-a3a1-89df1df61a04"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>judge_id</th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>relevance</th>\n",
              "      <th>lem_text</th>\n",
              "      <th>stem_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Appeal by special leave from the order dated  ...</td>\n",
              "      <td>0</td>\n",
              "      <td>appeal special leave order dated government pu...</td>\n",
              "      <td>appeal special leav order date govern punjab (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>From the Judgment and Order dated . .  of the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>judgment order dated . . bombay high court app...</td>\n",
              "      <td>judgment order date . . bombay high court appe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Appeal from the judgment and decree dated rd/t...</td>\n",
              "      <td>0</td>\n",
              "      <td>appeal judgment decree dated rd/th calcutta hi...</td>\n",
              "      <td>appeal judgment decre date rd/th calcutta high...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>of .</td>\n",
              "      <td>0</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>From the Judgment and order dated . .  of the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>judgment order dated . . allahabad high court ...</td>\n",
              "      <td>judgment order date . . allahabad high court c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   judge_id  ...                                          stem_text\n",
              "0         1  ...  appeal special leav order date govern punjab (...\n",
              "1         2  ...  judgment order date . . bombay high court appe...\n",
              "2         3  ...  appeal judgment decre date rd/th calcutta high...\n",
              "3         4  ...                                                  .\n",
              "4         5  ...  judgment order date . . allahabad high court c...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['judge_id'].max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoRhldRMu4E7",
        "outputId": "d6afc7e1-3c3d-4890-a2cc-f7eb536a138b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df[df['judge_id'] <= 400]\n",
        "df2 = df[df['judge_id'] > 400]\n",
        "\n",
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "e0zmZ4SVwEfI",
        "outputId": "7fd16c12-4079-4e2b-ea3f-1344bbc255b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>judge_id</th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>relevance</th>\n",
              "      <th>lem_text</th>\n",
              "      <th>stem_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Appeal by special leave from the order dated  ...</td>\n",
              "      <td>0</td>\n",
              "      <td>appeal special leave order dated government pu...</td>\n",
              "      <td>appeal special leav order date govern punjab (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>From the Judgment and Order dated . .  of the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>judgment order dated . . bombay high court app...</td>\n",
              "      <td>judgment order date . . bombay high court appe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Appeal from the judgment and decree dated rd/t...</td>\n",
              "      <td>0</td>\n",
              "      <td>appeal judgment decree dated rd/th calcutta hi...</td>\n",
              "      <td>appeal judgment decre date rd/th calcutta high...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>of .</td>\n",
              "      <td>0</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>From the Judgment and order dated . .  of the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>judgment order dated . . allahabad high court ...</td>\n",
              "      <td>judgment order date . . allahabad high court c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72187</th>\n",
              "      <td>27</td>\n",
              "      <td>2541</td>\n",
              "      <td>The petitioner before us does not complain tha...</td>\n",
              "      <td>0</td>\n",
              "      <td>petitioner u complain got proper grounds.</td>\n",
              "      <td>petition us complain got proper grounds.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72188</th>\n",
              "      <td>27</td>\n",
              "      <td>2542</td>\n",
              "      <td>Further the period of his detention under the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>period detention impugned act gone beyond thre...</td>\n",
              "      <td>period detent impugn act gone beyond three mon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72189</th>\n",
              "      <td>27</td>\n",
              "      <td>2543</td>\n",
              "      <td>Petition dismissed.</td>\n",
              "      <td>0</td>\n",
              "      <td>petition dismissed.</td>\n",
              "      <td>petit dismissed.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72190</th>\n",
              "      <td>27</td>\n",
              "      <td>2544</td>\n",
              "      <td>Agent for the petitioner: S. Subrahmanyam.</td>\n",
              "      <td>0</td>\n",
              "      <td>agent petitioner: s. subrahmanyam.</td>\n",
              "      <td>agent petitioner: s. subrahmanyam.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72191</th>\n",
              "      <td>27</td>\n",
              "      <td>2545</td>\n",
              "      <td>Agent for the State of Madras and Union of Ind...</td>\n",
              "      <td>0</td>\n",
              "      <td>agent state madras union india: p. a. mehta.</td>\n",
              "      <td>agent state madra union india: p. a. mehta.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59880 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       judge_id  ...                                          stem_text\n",
              "0             1  ...  appeal special leav order date govern punjab (...\n",
              "1             2  ...  judgment order date . . bombay high court appe...\n",
              "2             3  ...  appeal judgment decre date rd/th calcutta high...\n",
              "3             4  ...                                                  .\n",
              "4             5  ...  judgment order date . . allahabad high court c...\n",
              "...         ...  ...                                                ...\n",
              "72187        27  ...           petition us complain got proper grounds.\n",
              "72188        27  ...  period detent impugn act gone beyond three mon...\n",
              "72189        27  ...                                   petit dismissed.\n",
              "72190        27  ...                 agent petitioner: s. subrahmanyam.\n",
              "72191        27  ...        agent state madra union india: p. a. mehta.\n",
              "\n",
              "[59880 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "W8VN471NxzOt",
        "outputId": "949cf3b2-408f-475c-9131-ae76d7018014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>judge_id</th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>relevance</th>\n",
              "      <th>lem_text</th>\n",
              "      <th>stem_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>401</td>\n",
              "      <td>1</td>\n",
              "      <td>Appeal by special leave from the judgment and ...</td>\n",
              "      <td>0</td>\n",
              "      <td>appeal special leave judgment order dated _the...</td>\n",
              "      <td>appeal special leav judgment order date _the m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>402</td>\n",
              "      <td>1</td>\n",
              "      <td>Appeal from Judgment and Order dated the th da...</td>\n",
              "      <td>0</td>\n",
              "      <td>appeal judgment order dated th day june high c...</td>\n",
              "      <td>appeal judgment order date th day june high co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>403</td>\n",
              "      <td>1</td>\n",
              "      <td>Appeal by Special leave from the Judgment and ...</td>\n",
              "      <td>0</td>\n",
              "      <td>appeal special leave judgment order dated rd j...</td>\n",
              "      <td>appeal special leav judgment order date rd jan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>404</td>\n",
              "      <td>1</td>\n",
              "      <td>From the Judgment and Order dated . .  of the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>judgment order dated . . andhra pradesh admini...</td>\n",
              "      <td>judgment order date . . andhra pradesh adminis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>405</td>\n",
              "      <td>1</td>\n",
              "      <td>Appeal by Special Leave from the Award of the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>appeal special leave award industrial tribunal...</td>\n",
              "      <td>appeal special leav award industri tribun guja...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69217</th>\n",
              "      <td>409</td>\n",
              "      <td>1201</td>\n",
              "      <td>The interim orders passed by this Court are va...</td>\n",
              "      <td>0</td>\n",
              "      <td>interim order passed court vacated.</td>\n",
              "      <td>interim order pass court vacated.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69223</th>\n",
              "      <td>409</td>\n",
              "      <td>1202</td>\n",
              "      <td>The amount of rupees  which the Indian shareho...</td>\n",
              "      <td>0</td>\n",
              "      <td>amount rupee indian shareholder directed pay h...</td>\n",
              "      <td>amount rupe indian sharehold direct pay hold c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69229</th>\n",
              "      <td>409</td>\n",
              "      <td>1203</td>\n",
              "      <td>The interim Board of Directors shall forthwith...</td>\n",
              "      <td>1</td>\n",
              "      <td>interim board director shall forthwith hand ch...</td>\n",
              "      <td>interim board director shall forthwith hand ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69235</th>\n",
              "      <td>409</td>\n",
              "      <td>1204</td>\n",
              "      <td>After taking the charge from the interim Board...</td>\n",
              "      <td>0</td>\n",
              "      <td>taking charge interim board board director tak...</td>\n",
              "      <td>take charg interim board board director take e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69241</th>\n",
              "      <td>409</td>\n",
              "      <td>1205</td>\n",
              "      <td>N. V. K. Appeals allowed.</td>\n",
              "      <td>0</td>\n",
              "      <td>n. v. k. appeal allowed.</td>\n",
              "      <td>n. v. k. appeal allowed.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12312 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       judge_id  ...                                          stem_text\n",
              "400         401  ...  appeal special leav judgment order date _the m...\n",
              "401         402  ...  appeal judgment order date th day june high co...\n",
              "402         403  ...  appeal special leav judgment order date rd jan...\n",
              "403         404  ...  judgment order date . . andhra pradesh adminis...\n",
              "404         405  ...  appeal special leav award industri tribun guja...\n",
              "...         ...  ...                                                ...\n",
              "69217       409  ...                  interim order pass court vacated.\n",
              "69223       409  ...  amount rupe indian sharehold direct pay hold c...\n",
              "69229       409  ...  interim board director shall forthwith hand ch...\n",
              "69235       409  ...  take charg interim board board director take e...\n",
              "69241       409  ...                           n. v. k. appeal allowed.\n",
              "\n",
              "[12312 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjVZjMGufJ77"
      },
      "source": [
        "max_classes = len(df1.relevance.unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nK9TrAHfSQg"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "result = shuffle(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krpku0w1fbJX"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(df1.sentence, df1.relevance, \n",
        "                                                    test_size = 0.1, random_state = 42, stratify =df1.relevance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rFT-Zm4foeL"
      },
      "source": [
        "bert_model_name = 'bert_en_uncased_L-12_H-768_A-12'\n",
        "bert_model_link = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4'\n",
        "bert_model_preprocessing_link = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "481xglaWfqA1"
      },
      "source": [
        "bert_preprocess_model = hub.KerasLayer(bert_model_preprocessing_link)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1bQTmcpfuSJ"
      },
      "source": [
        "bert_model = hub.KerasLayer(bert_model_link)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grN9Gx_YfyEe"
      },
      "source": [
        "def build_classifier_model():\n",
        "    text_input = tf.keras.layers.Input(shape=(), dtype = tf.string, name='input-text')\n",
        "    preprocessing_layer = hub.KerasLayer(bert_model_preprocessing_link, name='bert-preprocessing')\n",
        "    encoder_inputs = preprocessing_layer(text_input)\n",
        "    encoder = hub.KerasLayer(bert_model_link, trainable=True, name='bert-encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "    net = outputs['pooled_output']\n",
        "    net = tf.keras.layers.Dropout(0.1)(net)\n",
        "    net = Dense(units= 512, activation='relu')(net)\n",
        "    net = tf.keras.layers.Dropout(0.1)(net)\n",
        "    net = Dense(units=max_classes, activation='softmax', name='classifer')(net)\n",
        "    return tf.keras.Model(text_input, net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVHgDE68f2n7"
      },
      "source": [
        "classifier_model = build_classifier_model()\n",
        "# bert_raw_result = classifier_model(tf.constant(sample_text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZEVdybJf-WK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b554b930-58b2-47c2-ab1e-78e18f1270a6"
      },
      "source": [
        "classifier_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input-text (InputLayer)        [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " bert-preprocessing (KerasLayer  {'input_type_ids':   0          ['input-text[0][0]']             \n",
            " )                              (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128),                                                          \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " bert-encoder (KerasLayer)      {'default': (None,   109482241   ['bert-preprocessing[0][0]',     \n",
            "                                768),                             'bert-preprocessing[0][1]',     \n",
            "                                 'sequence_output':               'bert-preprocessing[0][2]']     \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 128, 768),                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768)}                                                       \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 768)          0           ['bert-encoder[0][13]']          \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          393728      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 512)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " classifer (Dense)              (None, 2)            1026        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,876,995\n",
            "Trainable params: 109,876,994\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGvjsFnOgExy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0f4457d-bdc7-4e71-a0c7-b0c1cc9339a7"
      },
      "source": [
        "%time\n",
        "encoded_labels_train = to_categorical(Y_train, num_classes=max_classes)\n",
        "encoded_labels_test = to_categorical(Y_test, num_classes=max_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 8.11 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9ZigSpXgG4a"
      },
      "source": [
        "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
        "\n",
        "EPOCHS = 3\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
        "batch_size = 32\n",
        "\n",
        "num_train_steps =  len((df1.relevance) // batch_size) * EPOCHS\n",
        "lr_scheduler = PolynomialDecay(initial_learning_rate=5e-5,\n",
        "                               end_learning_rate=0.,\n",
        "                               decay_steps=num_train_steps\n",
        "                               )\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "opt = Adam(learning_rate=lr_scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSixERbcgezx",
        "outputId": "4477c045-3317-484c-afa9-ca8cefa52551"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "!mkdir checkpoints\n",
        "\n",
        "MyCheckpoint = ModelCheckpoint('/content/checkpoints',\n",
        "                               monitor = 'val_categorical_accuracy',\n",
        "                               verbose = 1,\n",
        "                               save_best_only = True,\n",
        "                               save_weights_only = False)\n",
        "\n",
        "MyEarlyStopping = EarlyStopping(patience =1,\n",
        "                                monitor='val_categorical_accuracy',\n",
        "                                restore_best_weights = True,\n",
        "                                verbose = 1)\n",
        "\n",
        "import os\n",
        "os.path.exists('/content/checkpoints')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVCS0cHdgj1G",
        "outputId": "1e85f157-6d42-4fe3-8dee-f6a5f3cb95b5"
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weights_array = class_weight.compute_class_weight(class_weight='balanced'\n",
        "                                               ,classes=np.unique(df1.relevance)\n",
        "                                               ,y=df1.relevance)\n",
        "\n",
        "class_weights_array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.6463312, 2.2084532])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITubrwLvgxbQ",
        "outputId": "3fac0b93-e07d-4dee-9ca7-e7b0cbf6d579"
      },
      "source": [
        "class_weights = {i : class_weights_array[i] for i in range(len(class_weights_array))}\n",
        "class_weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.6463311961660514, 1: 2.2084531976100905}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69y_zcL6g1Pj"
      },
      "source": [
        "import tensorflow_addons as tfa\n",
        "\n",
        "macro_f1 = tfa.metrics.F1Score(num_classes=max_classes, average='macro')\n",
        "micro_f1 = tfa.metrics.F1Score(num_classes=max_classes, average='micro')\n",
        "weighted_f1 = tfa.metrics.F1Score(num_classes=max_classes, average='weighted')\n",
        "precision = tf.metrics.Precision()\n",
        "recall = tf.metrics.Recall()\n",
        "categorical_accuracry = tf.metrics.CategoricalAccuracy()\n",
        "\n",
        "metrics = [categorical_accuracry, micro_f1, precision, recall]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BUDkx51g3XB"
      },
      "source": [
        "classifier_model.compile(optimizer= opt,\n",
        "              loss= loss,\n",
        "              metrics = metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTCjS6jXg9L5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "742756e6-3769-43bc-a06f-650e4d494810"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, encoded_labels_train)).shuffle(40000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, encoded_labels_test)).shuffle(40000).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-dae24b813600>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_labels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_labels_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'encoded_labels_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lgs5PbthL0X",
        "outputId": "61b7e66f-0c2f-456b-f472-9d0c48f9e932"
      },
      "source": [
        "classifier_model.fit(train_dataset,\n",
        "                     validation_data=test_dataset,\n",
        "                 epochs = EPOCHS,\n",
        "                 verbose = 1,\n",
        "                 class_weight=class_weights,\n",
        "                 callbacks = [MyCheckpoint, MyEarlyStopping]\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1685/1685 [==============================] - ETA: 0s - loss: 0.6485 - categorical_accuracy: 0.5897 - f1_score: 0.5897 - precision: 0.5897 - recall: 0.5897\n",
            "Epoch 00001: val_categorical_accuracy improved from -inf to 0.45892, saving model to /content/checkpoints\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) input-text with unsupported characters which will be renamed to input_text in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 915). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/checkpoints/assets\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/checkpoints/assets\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1685/1685 [==============================] - 2834s 2s/step - loss: 0.6485 - categorical_accuracy: 0.5897 - f1_score: 0.5897 - precision: 0.5897 - recall: 0.5897 - val_loss: 0.7694 - val_categorical_accuracy: 0.4589 - val_f1_score: 0.4589 - val_precision: 0.4589 - val_recall: 0.4589\n",
            "Epoch 2/3\n",
            "1685/1685 [==============================] - ETA: 0s - loss: 0.5542 - categorical_accuracy: 0.6964 - f1_score: 0.6964 - precision: 0.6964 - recall: 0.6964\n",
            "Epoch 00002: val_categorical_accuracy improved from 0.45892 to 0.68921, saving model to /content/checkpoints\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) input-text with unsupported characters which will be renamed to input_text in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 915). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/checkpoints/assets\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/checkpoints/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1685/1685 [==============================] - 2820s 2s/step - loss: 0.5542 - categorical_accuracy: 0.6964 - f1_score: 0.6964 - precision: 0.6964 - recall: 0.6964 - val_loss: 0.5664 - val_categorical_accuracy: 0.6892 - val_f1_score: 0.6892 - val_precision: 0.6892 - val_recall: 0.6892\n",
            "Epoch 3/3\n",
            "1685/1685 [==============================] - ETA: 0s - loss: 0.4228 - categorical_accuracy: 0.7913 - f1_score: 0.7913 - precision: 0.7913 - recall: 0.7913\n",
            "Epoch 00003: val_categorical_accuracy improved from 0.68921 to 0.70391, saving model to /content/checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) input-text with unsupported characters which will be renamed to input_text in the SavedModel.\n",
            "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 915). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/checkpoints/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/checkpoints/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1685/1685 [==============================] - 2812s 2s/step - loss: 0.4228 - categorical_accuracy: 0.7913 - f1_score: 0.7913 - precision: 0.7913 - recall: 0.7913 - val_loss: 0.6615 - val_categorical_accuracy: 0.7039 - val_f1_score: 0.7039 - val_precision: 0.7039 - val_recall: 0.7039\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9488ae8cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owcR5YRhhTy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "754a367f-aea1-434b-aebe-273a6cd6cab8"
      },
      "source": [
        "classifier_model.save('BERT-Model.h5') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMthbmHPlHbU",
        "outputId": "82ebd15c-35c5-4e52-8abe-8d9ae1dc41b4"
      },
      "source": [
        "y_preds = np.argmax(classifier_model.predict(df2.sentence), axis=1)\n",
        "y_preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2['pred_relevance'] = y_preds\n",
        "df2"
      ],
      "metadata": {
        "id": "u05RkLgAzQRC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "outputId": "417d61bd-2713-4474-d96f-77213e2b2f88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>judge_id</th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>relevance</th>\n",
              "      <th>lem_text</th>\n",
              "      <th>stem_text</th>\n",
              "      <th>pred_relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>401</td>\n",
              "      <td>1</td>\n",
              "      <td>Appeal by special leave from the judgment and ...</td>\n",
              "      <td>0</td>\n",
              "      <td>appeal special leave judgment order dated _the...</td>\n",
              "      <td>appeal special leav judgment order date _the m...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>402</td>\n",
              "      <td>1</td>\n",
              "      <td>Appeal from Judgment and Order dated the th da...</td>\n",
              "      <td>0</td>\n",
              "      <td>appeal judgment order dated th day june high c...</td>\n",
              "      <td>appeal judgment order date th day june high co...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>403</td>\n",
              "      <td>1</td>\n",
              "      <td>Appeal by Special leave from the Judgment and ...</td>\n",
              "      <td>0</td>\n",
              "      <td>appeal special leave judgment order dated rd j...</td>\n",
              "      <td>appeal special leav judgment order date rd jan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>404</td>\n",
              "      <td>1</td>\n",
              "      <td>From the Judgment and Order dated . .  of the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>judgment order dated . . andhra pradesh admini...</td>\n",
              "      <td>judgment order date . . andhra pradesh adminis...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>405</td>\n",
              "      <td>1</td>\n",
              "      <td>Appeal by Special Leave from the Award of the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>appeal special leave award industrial tribunal...</td>\n",
              "      <td>appeal special leav award industri tribun guja...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69217</th>\n",
              "      <td>409</td>\n",
              "      <td>1201</td>\n",
              "      <td>The interim orders passed by this Court are va...</td>\n",
              "      <td>0</td>\n",
              "      <td>interim order passed court vacated.</td>\n",
              "      <td>interim order pass court vacated.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69223</th>\n",
              "      <td>409</td>\n",
              "      <td>1202</td>\n",
              "      <td>The amount of rupees  which the Indian shareho...</td>\n",
              "      <td>0</td>\n",
              "      <td>amount rupee indian shareholder directed pay h...</td>\n",
              "      <td>amount rupe indian sharehold direct pay hold c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69229</th>\n",
              "      <td>409</td>\n",
              "      <td>1203</td>\n",
              "      <td>The interim Board of Directors shall forthwith...</td>\n",
              "      <td>1</td>\n",
              "      <td>interim board director shall forthwith hand ch...</td>\n",
              "      <td>interim board director shall forthwith hand ch...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69235</th>\n",
              "      <td>409</td>\n",
              "      <td>1204</td>\n",
              "      <td>After taking the charge from the interim Board...</td>\n",
              "      <td>0</td>\n",
              "      <td>taking charge interim board board director tak...</td>\n",
              "      <td>take charg interim board board director take e...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69241</th>\n",
              "      <td>409</td>\n",
              "      <td>1205</td>\n",
              "      <td>N. V. K. Appeals allowed.</td>\n",
              "      <td>0</td>\n",
              "      <td>n. v. k. appeal allowed.</td>\n",
              "      <td>n. v. k. appeal allowed.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12312 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       judge_id  ...  pred_relevance\n",
              "400         401  ...               1\n",
              "401         402  ...               1\n",
              "402         403  ...               1\n",
              "403         404  ...               1\n",
              "404         405  ...               1\n",
              "...         ...  ...             ...\n",
              "69217       409  ...               1\n",
              "69223       409  ...               1\n",
              "69229       409  ...               1\n",
              "69235       409  ...               1\n",
              "69241       409  ...               1\n",
              "\n",
              "[12312 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(df2.relevance,df2.pred_relevance))\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf_mat = confusion_matrix(list(df2.relevance), list(df2['pred_relevance']))\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
        "            xticklabels=set(df2.relevance), yticklabels=set(df2.relevance))\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.title('BERT(lemm) Task2 relevance  oversampled')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ChZiLuxuzjvX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 777
        },
        "outputId": "900a9931-a984-4c31-ee87-cbbd40abff1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.04      0.07      9288\n",
            "           1       0.25      0.98      0.40      3024\n",
            "\n",
            "    accuracy                           0.27     12312\n",
            "   macro avg       0.55      0.51      0.23     12312\n",
            "weighted avg       0.70      0.27      0.15     12312\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_file= pd.DataFrame(columns=['judge_id', 'summary', 'pred_summary'])\n",
        "for i in range(100):\n",
        "      summary_file= summary_file.append({'judge_id': i+401,  'summary': '', 'pred_summary': ''}, ignore_index=True)"
      ],
      "metadata": {
        "id": "v5InR76Wc-px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df2.index:\n",
        "  if df2['relevance'][i]:\n",
        "    summary_file['summary'][df2['judge_id'][i]-401]+=(df2['sentence'][i])\n",
        "  if df2['pred_relevance'][i]:\n",
        "    summary_file['pred_summary'][df2['judge_id'][i]-401]+=(df2['sentence'][i])\n",
        "\n",
        "summary_file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "AY-OJJAic-sv",
        "outputId": "2876c517-b8be-40a8-8bbf-605bf38e383c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>judge_id</th>\n",
              "      <th>summary</th>\n",
              "      <th>pred_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>401</td>\n",
              "      <td>The appellant is a firm consisting of six part...</td>\n",
              "      <td>Appeal by special leave from the judgment and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>402</td>\n",
              "      <td>Sannyasi charan Sadhukhan died in  and his son...</td>\n",
              "      <td>Appeal from Judgment and Order dated the th da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>403</td>\n",
              "      <td>The following question of law had been referre...</td>\n",
              "      <td>Appeal by Special leave from the Judgment and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>404</td>\n",
              "      <td>Special leave granted.Pending prosecution with...</td>\n",
              "      <td>From the Judgment and Order dated . .  of the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>405</td>\n",
              "      <td>In the case of the Alembic Glass Industries li...</td>\n",
              "      <td>Appeal by Special Leave from the Award of the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>496</td>\n",
              "      <td>Punjab Excise Act  has been extended to Delhi....</td>\n",
              "      <td>From the Judgment and Order dated -- of the De...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>497</td>\n",
              "      <td>In support of his first contention reliance wa...</td>\n",
              "      <td>Appeal from the Judgment and Decree dated the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>498</td>\n",
              "      <td>These appointments seem to have been made vari...</td>\n",
              "      <td>From the Judgment and Order dated . .  of the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>499</td>\n",
              "      <td>The revenue authorities sanctioned mutation of...</td>\n",
              "      <td>Appeal from the judgment and decree dated   of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>500</td>\n",
              "      <td>This is a tenant's appeal by special leave aga...</td>\n",
              "      <td>R. K. Garg S. K. Gambhir Mrs. Ashok Mahajan an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   judge_id  ...                                       pred_summary\n",
              "0       401  ...  Appeal by special leave from the judgment and ...\n",
              "1       402  ...  Appeal from Judgment and Order dated the th da...\n",
              "2       403  ...  Appeal by Special leave from the Judgment and ...\n",
              "3       404  ...  From the Judgment and Order dated . .  of the ...\n",
              "4       405  ...  Appeal by Special Leave from the Award of the ...\n",
              "..      ...  ...                                                ...\n",
              "95      496  ...  From the Judgment and Order dated -- of the De...\n",
              "96      497  ...  Appeal from the Judgment and Decree dated the ...\n",
              "97      498  ...  From the Judgment and Order dated . .  of the ...\n",
              "98      499  ...  Appeal from the judgment and decree dated   of...\n",
              "99      500  ...  R. K. Garg S. K. Gambhir Mrs. Ashok Mahajan an...\n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bert-extractive-summarizer"
      ],
      "metadata": {
        "id": "J8Z8z7aOyK5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from summarizer import Summarizer\n",
        "model = Summarizer()\n",
        "\n",
        "for i in summary_file.index:\n",
        "    sumx = model(summary_file.summary[i], min_length=20)\n",
        "    summary_file.summary[i] = \"\".join(sumx)\n",
        "    sumz = model(summary_file.pred_summary[i], min_length=20)\n",
        "    summary_file.pred_summary[i] = \"\".join(sumz)"
      ],
      "metadata": {
        "id": "CTPKJgihyPW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge\n",
        "\n",
        "from rouge import Rouge\n",
        "\n",
        "rouge = Rouge()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TC-RlcPSgIEd",
        "outputId": "ccc8868d-5d01-4123-ce14-e42f6a6e2a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_scores= pd.DataFrame(columns=['r1_f', 'r1_p', 'r1_r', 'r2_f', 'r2_p', 'r2_r', 'rl_f', 'rl_p', 'rl_r'])\n",
        "\n",
        "#for i in range(100):\n",
        "  #rouge_scores= rouge_scores.append({'r1_f': 0.0 , 'r1_p': 0.0 , 'r1_r': 0.0 , 'r2_f': 0.0 , 'r2_p': 0.0 , 'r2_r': 0.0 , 'rl_f': 0.0 , 'rl_p': 0.0 , 'rl_r': 0.0 }, ignore_index=True)\n",
        "\n",
        "\n",
        "for i in summary_file.index:\n",
        "    if(summary_file['summary'][i]==''):\n",
        "      summary_file['summary'][i]+=\"Empty\"\n",
        "    if(summary_file['pred_summary'][i]==''):\n",
        "      summary_file['pred_summary'][i]+=\"Empty\"\n",
        "    scores = rouge.get_scores(summary_file['pred_summary'][i], summary_file['summary'][i])\n",
        "    rouge_scores= rouge_scores.append({'r1_f': scores[0]['rouge-1']['f'] , 'r1_p': scores[0]['rouge-1']['p'] , 'r1_r': scores[0]['rouge-1']['r'] , 'r2_f': scores[0]['rouge-2']['f'] , 'r2_p': scores[0]['rouge-2']['p'] , 'r2_r': scores[0]['rouge-2']['r'] , 'rl_f': scores[0]['rouge-l']['f'] , 'rl_p': scores[0]['rouge-l']['p'] , 'rl_r': scores[0]['rouge-l']['r'] }, ignore_index=True)\n",
        "\n",
        "\n",
        "rouge_scores"
      ],
      "metadata": {
        "id": "oCxW9XZelFst",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "b5b29263-995c-4f63-f7f1-2c57f5832f6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>r1_f</th>\n",
              "      <th>r1_p</th>\n",
              "      <th>r1_r</th>\n",
              "      <th>r2_f</th>\n",
              "      <th>r2_p</th>\n",
              "      <th>r2_r</th>\n",
              "      <th>rl_f</th>\n",
              "      <th>rl_p</th>\n",
              "      <th>rl_r</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.632429</td>\n",
              "      <td>0.462447</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.526182</td>\n",
              "      <td>0.359762</td>\n",
              "      <td>0.979096</td>\n",
              "      <td>0.632429</td>\n",
              "      <td>0.462447</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.373529</td>\n",
              "      <td>0.229656</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.279420</td>\n",
              "      <td>0.162948</td>\n",
              "      <td>0.979675</td>\n",
              "      <td>0.373529</td>\n",
              "      <td>0.229656</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.661342</td>\n",
              "      <td>0.496999</td>\n",
              "      <td>0.988067</td>\n",
              "      <td>0.565142</td>\n",
              "      <td>0.398814</td>\n",
              "      <td>0.969466</td>\n",
              "      <td>0.659744</td>\n",
              "      <td>0.495798</td>\n",
              "      <td>0.985680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.674965</td>\n",
              "      <td>0.509395</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.587622</td>\n",
              "      <td>0.418756</td>\n",
              "      <td>0.984716</td>\n",
              "      <td>0.674965</td>\n",
              "      <td>0.509395</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.513919</td>\n",
              "      <td>0.345821</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.431579</td>\n",
              "      <td>0.276249</td>\n",
              "      <td>0.985972</td>\n",
              "      <td>0.513919</td>\n",
              "      <td>0.345821</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>0.755270</td>\n",
              "      <td>0.616305</td>\n",
              "      <td>0.975148</td>\n",
              "      <td>0.700589</td>\n",
              "      <td>0.551662</td>\n",
              "      <td>0.959659</td>\n",
              "      <td>0.753437</td>\n",
              "      <td>0.614809</td>\n",
              "      <td>0.972781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>0.467049</td>\n",
              "      <td>0.304673</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.372067</td>\n",
              "      <td>0.229497</td>\n",
              "      <td>0.982301</td>\n",
              "      <td>0.467049</td>\n",
              "      <td>0.304673</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.622159</td>\n",
              "      <td>0.457203</td>\n",
              "      <td>0.973333</td>\n",
              "      <td>0.500414</td>\n",
              "      <td>0.340474</td>\n",
              "      <td>0.943750</td>\n",
              "      <td>0.619318</td>\n",
              "      <td>0.455115</td>\n",
              "      <td>0.968889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>0.516046</td>\n",
              "      <td>0.348354</td>\n",
              "      <td>0.995050</td>\n",
              "      <td>0.440843</td>\n",
              "      <td>0.284321</td>\n",
              "      <td>0.980769</td>\n",
              "      <td>0.516046</td>\n",
              "      <td>0.348354</td>\n",
              "      <td>0.995050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.611326</td>\n",
              "      <td>0.442684</td>\n",
              "      <td>0.987526</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        r1_f      r1_p      r1_r  ...      rl_f      rl_p      rl_r\n",
              "0   0.632429  0.462447  1.000000  ...  0.632429  0.462447  1.000000\n",
              "1   0.373529  0.229656  1.000000  ...  0.373529  0.229656  1.000000\n",
              "2   0.661342  0.496999  0.988067  ...  0.659744  0.495798  0.985680\n",
              "3   0.674965  0.509395  1.000000  ...  0.674965  0.509395  1.000000\n",
              "4   0.513919  0.345821  1.000000  ...  0.513919  0.345821  1.000000\n",
              "..       ...       ...       ...  ...       ...       ...       ...\n",
              "95  0.755270  0.616305  0.975148  ...  0.753437  0.614809  0.972781\n",
              "96  0.467049  0.304673  1.000000  ...  0.467049  0.304673  1.000000\n",
              "97  0.622159  0.457203  0.973333  ...  0.619318  0.455115  0.968889\n",
              "98  0.516046  0.348354  0.995050  ...  0.516046  0.348354  0.995050\n",
              "99  0.714286  0.555556  1.000000  ...  0.714286  0.555556  1.000000\n",
              "\n",
              "[100 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r1mean_f = rouge_scores['r1_f'].mean()\n",
        "print('rouge-1 AVERAGE_F is',r1mean_f)\n",
        "r1mean_p = rouge_scores['r1_p'].mean()\n",
        "print('rouge-1 AVERAGE_P is',r1mean_p)\n",
        "r1mean_r = rouge_scores['r1_r'].mean()\n",
        "print('rouge-1 AVERAGE_R is',r1mean_r)\n",
        "r2mean_f = rouge_scores['r2_f'].mean()\n",
        "print('rouge-2 AVERAGE_F is',r2mean_f)\n",
        "r2mean_p = rouge_scores['r2_p'].mean()\n",
        "print('rouge-2 AVERAGE_P is',r2mean_p)\n",
        "r2mean_r = rouge_scores['r2_r'].mean()\n",
        "print('rouge-2 AVERAGE_R is',r2mean_r)\n",
        "rlmean_f = rouge_scores['rl_f'].mean()\n",
        "print('rouge-l AVERAGE_F is',rlmean_f)\n",
        "rlmean_p = rouge_scores['rl_p'].mean()\n",
        "print('rouge-l AVERAGE_P is',rlmean_p)\n",
        "rlmean_r = rouge_scores['rl_r'].mean()\n",
        "print('rouge-l AVERAGE_R is',rlmean_r)"
      ],
      "metadata": {
        "id": "sHe-9Qu6lJP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "957ccd47-fd11-4ca6-a619-11da1f3537be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rouge-1 AVERAGE_F is 0.5453772846084265\n",
            "rouge-1 AVERAGE_P is 0.3906670615672539\n",
            "rouge-1 AVERAGE_R is 0.9814606195442309\n",
            "rouge-2 AVERAGE_F is 0.4498077708113165\n",
            "rouge-2 AVERAGE_P is 0.3070515332073615\n",
            "rouge-2 AVERAGE_R is 0.9622786611524502\n",
            "rouge-l AVERAGE_F is 0.5446139951396699\n",
            "rouge-l AVERAGE_P is 0.39013355665143784\n",
            "rouge-l AVERAGE_R is 0.9800661184754579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PU5CI02QpeBd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}